nohup: ignoring input
Using TensorFlow backend.
2019-05-09 23:31:06.020467: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-05-09 23:31:06.049712: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194840000 Hz
2019-05-09 23:31:06.052218: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x41dc970 executing computations on platform Host. Devices:
2019-05-09 23:31:06.052257: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-09 23:31:06.053490: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> node0:2272}
2019-05-09 23:31:06.053514: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> node0:2273, 1 -> localhost:2274, 2 -> node2:2275}
2019-05-09 23:31:06.057182: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2274
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:132: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:133: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:220: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
INFO:tensorflow:Running local_init_op.
2019-05-09 23:31:09.693005: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 011964c2446a4dde with config: 
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting queue runners.
worker
Variables initialized ...
running epochs
Step 10, Minibatch Loss= 3.6374, Training Accuracy= 0.110
Step 20, Minibatch Loss= 3.0064, Training Accuracy= 0.120
Step 30, Minibatch Loss= 2.1917, Training Accuracy= 0.310
Step 40, Minibatch Loss= 1.8622, Training Accuracy= 0.340
Step 50, Minibatch Loss= 1.6428, Training Accuracy= 0.430
Step 60, Minibatch Loss= 1.5873, Training Accuracy= 0.430
Step 70, Minibatch Loss= 1.2394, Training Accuracy= 0.550
Step 80, Minibatch Loss= 0.8910, Training Accuracy= 0.690
Step 90, Minibatch Loss= 0.8934, Training Accuracy= 0.690
Step 100, Minibatch Loss= 0.9664, Training Accuracy= 0.660
Step 110, Minibatch Loss= 0.6930, Training Accuracy= 0.760
Step 120, Minibatch Loss= 0.7800, Training Accuracy= 0.670
Step 130, Minibatch Loss= 0.6643, Training Accuracy= 0.790
Step 140, Minibatch Loss= 0.5495, Training Accuracy= 0.800
Step 150, Minibatch Loss= 0.4962, Training Accuracy= 0.810
Step 160, Minibatch Loss= 0.6364, Training Accuracy= 0.730
Step 170, Minibatch Loss= 0.5064, Training Accuracy= 0.850
Step 180, Minibatch Loss= 0.4299, Training Accuracy= 0.850
Step 190, Minibatch Loss= 0.6234, Training Accuracy= 0.830
Step 200, Minibatch Loss= 0.4106, Training Accuracy= 0.870
Step 210, Minibatch Loss= 0.2061, Training Accuracy= 0.950
Step 220, Minibatch Loss= 0.3965, Training Accuracy= 0.860
Step 230, Minibatch Loss= 0.3203, Training Accuracy= 0.900
Step 240, Minibatch Loss= 0.3402, Training Accuracy= 0.900
Step 250, Minibatch Loss= 0.3077, Training Accuracy= 0.920
Step 260, Minibatch Loss= 0.3099, Training Accuracy= 0.900
Step 270, Minibatch Loss= 0.1479, Training Accuracy= 0.950
Step 280, Minibatch Loss= 0.3318, Training Accuracy= 0.890
Step 290, Minibatch Loss= 0.1777, Training Accuracy= 0.960
Step 300, Minibatch Loss= 0.3374, Training Accuracy= 0.900
Step 310, Minibatch Loss= 0.1495, Training Accuracy= 0.950
Step 320, Minibatch Loss= 0.2795, Training Accuracy= 0.910
Step 330, Minibatch Loss= 0.3528, Training Accuracy= 0.880
Step 340, Minibatch Loss= 0.1722, Training Accuracy= 0.950
Step 350, Minibatch Loss= 0.1921, Training Accuracy= 0.910
Step 360, Minibatch Loss= 0.2764, Training Accuracy= 0.880
Step 370, Minibatch Loss= 0.2490, Training Accuracy= 0.920
Step 380, Minibatch Loss= 0.2844, Training Accuracy= 0.920
Step 390, Minibatch Loss= 0.3431, Training Accuracy= 0.870
Step 400, Minibatch Loss= 0.3228, Training Accuracy= 0.920
Step 410, Minibatch Loss= 0.1431, Training Accuracy= 0.960
Step 420, Minibatch Loss= 0.2493, Training Accuracy= 0.920
Step 430, Minibatch Loss= 0.1614, Training Accuracy= 0.960
Step 440, Minibatch Loss= 0.0998, Training Accuracy= 0.990
Step 450, Minibatch Loss= 0.1531, Training Accuracy= 0.950
Step 460, Minibatch Loss= 0.1203, Training Accuracy= 0.950
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.2293, Training Accuracy= 0.960
Step 20, Minibatch Loss= 0.0526, Training Accuracy= 0.990
Step 30, Minibatch Loss= 0.3332, Training Accuracy= 0.910
Step 40, Minibatch Loss= 0.1080, Training Accuracy= 0.970
Step 50, Minibatch Loss= 0.1316, Training Accuracy= 0.960
Step 60, Minibatch Loss= 0.1604, Training Accuracy= 0.950
Step 70, Minibatch Loss= 0.0798, Training Accuracy= 0.980
Step 80, Minibatch Loss= 0.1275, Training Accuracy= 0.980
Step 90, Minibatch Loss= 0.1073, Training Accuracy= 0.960
Step 100, Minibatch Loss= 0.1543, Training Accuracy= 0.950
Step 110, Minibatch Loss= 0.1138, Training Accuracy= 0.940
Step 120, Minibatch Loss= 0.2169, Training Accuracy= 0.910
Step 130, Minibatch Loss= 0.1164, Training Accuracy= 0.970
Step 140, Minibatch Loss= 0.1529, Training Accuracy= 0.960
Step 150, Minibatch Loss= 0.1789, Training Accuracy= 0.950
Step 160, Minibatch Loss= 0.1165, Training Accuracy= 0.950
Step 170, Minibatch Loss= 0.0963, Training Accuracy= 0.980
Step 180, Minibatch Loss= 0.1474, Training Accuracy= 0.950
Step 190, Minibatch Loss= 0.1649, Training Accuracy= 0.960
Step 200, Minibatch Loss= 0.0854, Training Accuracy= 0.960
Step 210, Minibatch Loss= 0.0698, Training Accuracy= 0.980
Step 220, Minibatch Loss= 0.1098, Training Accuracy= 0.970
Step 230, Minibatch Loss= 0.1938, Training Accuracy= 0.940
Step 240, Minibatch Loss= 0.1248, Training Accuracy= 0.950
Step 250, Minibatch Loss= 0.0841, Training Accuracy= 0.990
Step 260, Minibatch Loss= 0.1520, Training Accuracy= 0.950
Step 270, Minibatch Loss= 0.1035, Training Accuracy= 0.970
Step 280, Minibatch Loss= 0.1190, Training Accuracy= 0.950
Step 290, Minibatch Loss= 0.0525, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.1300, Training Accuracy= 0.970
Step 310, Minibatch Loss= 0.0718, Training Accuracy= 0.980
Step 320, Minibatch Loss= 0.0615, Training Accuracy= 0.980
Step 330, Minibatch Loss= 0.0805, Training Accuracy= 0.970
Step 340, Minibatch Loss= 0.0577, Training Accuracy= 0.990
Step 350, Minibatch Loss= 0.0765, Training Accuracy= 0.980
Step 360, Minibatch Loss= 0.0899, Training Accuracy= 0.970
Step 370, Minibatch Loss= 0.0732, Training Accuracy= 0.980
Step 380, Minibatch Loss= 0.0851, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.1259, Training Accuracy= 0.950
Step 400, Minibatch Loss= 0.1731, Training Accuracy= 0.950
Step 410, Minibatch Loss= 0.0618, Training Accuracy= 0.980
Step 420, Minibatch Loss= 0.1760, Training Accuracy= 0.960
Step 430, Minibatch Loss= 0.0920, Training Accuracy= 0.980
Step 440, Minibatch Loss= 0.0309, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0480, Training Accuracy= 0.990
Step 460, Minibatch Loss= 0.0925, Training Accuracy= 0.960
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0992, Training Accuracy= 0.980
Step 20, Minibatch Loss= 0.0346, Training Accuracy= 0.990
Step 30, Minibatch Loss= 0.1630, Training Accuracy= 0.950
Step 40, Minibatch Loss= 0.0587, Training Accuracy= 0.980
Step 50, Minibatch Loss= 0.0759, Training Accuracy= 0.970
Step 60, Minibatch Loss= 0.0509, Training Accuracy= 0.980
Step 70, Minibatch Loss= 0.0561, Training Accuracy= 0.980
Step 80, Minibatch Loss= 0.0291, Training Accuracy= 1.000
Step 90, Minibatch Loss= 0.0868, Training Accuracy= 0.970
Step 100, Minibatch Loss= 0.1144, Training Accuracy= 0.970
Step 110, Minibatch Loss= 0.0687, Training Accuracy= 0.990
Step 120, Minibatch Loss= 0.1551, Training Accuracy= 0.960
Step 130, Minibatch Loss= 0.0784, Training Accuracy= 0.980
Step 140, Minibatch Loss= 0.1443, Training Accuracy= 0.960
Step 150, Minibatch Loss= 0.0789, Training Accuracy= 0.960
Step 160, Minibatch Loss= 0.1156, Training Accuracy= 0.950
Step 170, Minibatch Loss= 0.0686, Training Accuracy= 0.970
Step 180, Minibatch Loss= 0.0654, Training Accuracy= 0.970
Step 190, Minibatch Loss= 0.0740, Training Accuracy= 0.990
Step 200, Minibatch Loss= 0.0611, Training Accuracy= 0.980
Step 210, Minibatch Loss= 0.0433, Training Accuracy= 0.980
Step 220, Minibatch Loss= 0.1055, Training Accuracy= 0.950
Step 230, Minibatch Loss= 0.1251, Training Accuracy= 0.970
Step 240, Minibatch Loss= 0.1130, Training Accuracy= 0.940
Step 250, Minibatch Loss= 0.0706, Training Accuracy= 0.980
Step 260, Minibatch Loss= 0.0368, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0245, Training Accuracy= 1.000
Step 280, Minibatch Loss= 0.0304, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0239, Training Accuracy= 0.990
Step 300, Minibatch Loss= 0.0529, Training Accuracy= 0.990
Step 310, Minibatch Loss= 0.0289, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0344, Training Accuracy= 0.990
Step 330, Minibatch Loss= 0.0359, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0224, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0519, Training Accuracy= 0.980
Step 360, Minibatch Loss= 0.0330, Training Accuracy= 0.990
Step 370, Minibatch Loss= 0.0500, Training Accuracy= 0.980
Step 380, Minibatch Loss= 0.0879, Training Accuracy= 0.980
Step 390, Minibatch Loss= 0.1014, Training Accuracy= 0.950
Step 400, Minibatch Loss= 0.1230, Training Accuracy= 0.970
Step 410, Minibatch Loss= 0.0258, Training Accuracy= 0.990
Step 420, Minibatch Loss= 0.0675, Training Accuracy= 0.970
Step 430, Minibatch Loss= 0.0178, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0199, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0377, Training Accuracy= 0.990
Step 460, Minibatch Loss= 0.0731, Training Accuracy= 0.980
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0625, Training Accuracy= 0.990
Step 20, Minibatch Loss= 0.0096, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.1278, Training Accuracy= 0.960
Step 40, Minibatch Loss= 0.0231, Training Accuracy= 0.990
Step 50, Minibatch Loss= 0.0499, Training Accuracy= 0.980
Step 60, Minibatch Loss= 0.0559, Training Accuracy= 0.980
Step 70, Minibatch Loss= 0.0115, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0517, Training Accuracy= 0.990
Step 90, Minibatch Loss= 0.0588, Training Accuracy= 0.980
Step 100, Minibatch Loss= 0.0351, Training Accuracy= 1.000
Step 110, Minibatch Loss= 0.0225, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0937, Training Accuracy= 0.970
Step 130, Minibatch Loss= 0.0375, Training Accuracy= 0.990
Step 140, Minibatch Loss= 0.2848, Training Accuracy= 0.960
Step 150, Minibatch Loss= 0.0183, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0284, Training Accuracy= 0.990
Step 170, Minibatch Loss= 0.0561, Training Accuracy= 0.980
Step 180, Minibatch Loss= 0.0692, Training Accuracy= 0.980
Step 190, Minibatch Loss= 0.0668, Training Accuracy= 0.980
Step 200, Minibatch Loss= 0.0473, Training Accuracy= 0.980
Step 210, Minibatch Loss= 0.0070, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0701, Training Accuracy= 0.980
Step 230, Minibatch Loss= 0.2185, Training Accuracy= 0.950
Step 240, Minibatch Loss= 0.0362, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0460, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0187, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0346, Training Accuracy= 0.980
Step 280, Minibatch Loss= 0.0146, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0060, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0362, Training Accuracy= 0.990
Step 310, Minibatch Loss= 0.0201, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0355, Training Accuracy= 0.990
Step 330, Minibatch Loss= 0.0375, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0226, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0206, Training Accuracy= 0.990
Step 360, Minibatch Loss= 0.0518, Training Accuracy= 0.970
Step 370, Minibatch Loss= 0.0191, Training Accuracy= 1.000
Step 380, Minibatch Loss= 0.0622, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0277, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.1013, Training Accuracy= 0.980
Step 410, Minibatch Loss= 0.0161, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0442, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0295, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0064, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0365, Training Accuracy= 0.990
Step 460, Minibatch Loss= 0.0542, Training Accuracy= 0.980
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0537, Training Accuracy= 0.980
Step 20, Minibatch Loss= 0.0376, Training Accuracy= 0.980
Step 30, Minibatch Loss= 0.1331, Training Accuracy= 0.960
Step 40, Minibatch Loss= 0.0243, Training Accuracy= 0.990
Step 50, Minibatch Loss= 0.0377, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0949, Training Accuracy= 0.950
Step 70, Minibatch Loss= 0.0248, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0441, Training Accuracy= 0.980
Step 90, Minibatch Loss= 0.0388, Training Accuracy= 0.990
Step 100, Minibatch Loss= 0.0442, Training Accuracy= 0.980
Step 110, Minibatch Loss= 0.0254, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0941, Training Accuracy= 0.970
Step 130, Minibatch Loss= 0.0640, Training Accuracy= 0.980
Step 140, Minibatch Loss= 0.0603, Training Accuracy= 0.970
Step 150, Minibatch Loss= 0.0125, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0246, Training Accuracy= 0.990
Step 170, Minibatch Loss= 0.0474, Training Accuracy= 0.990
Step 180, Minibatch Loss= 0.0544, Training Accuracy= 0.970
Step 190, Minibatch Loss= 0.0405, Training Accuracy= 0.980
Step 200, Minibatch Loss= 0.0260, Training Accuracy= 0.990
Step 210, Minibatch Loss= 0.0072, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0468, Training Accuracy= 0.990
Step 230, Minibatch Loss= 0.1114, Training Accuracy= 0.980
Step 240, Minibatch Loss= 0.0545, Training Accuracy= 0.990
Step 250, Minibatch Loss= 0.1162, Training Accuracy= 0.970
Step 260, Minibatch Loss= 0.0884, Training Accuracy= 0.980
Step 270, Minibatch Loss= 0.0158, Training Accuracy= 1.000
Step 280, Minibatch Loss= 0.0209, Training Accuracy= 0.990
Step 290, Minibatch Loss= 0.0081, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0114, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.1113, Training Accuracy= 0.970
Step 320, Minibatch Loss= 0.0137, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0373, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0145, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0148, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0255, Training Accuracy= 0.980
Step 370, Minibatch Loss= 0.0848, Training Accuracy= 0.960
Step 380, Minibatch Loss= 0.0495, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0194, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.1164, Training Accuracy= 0.990
Step 410, Minibatch Loss= 0.0235, Training Accuracy= 0.990
Step 420, Minibatch Loss= 0.0659, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0521, Training Accuracy= 0.980
Step 440, Minibatch Loss= 0.0268, Training Accuracy= 0.990
Step 450, Minibatch Loss= 0.0366, Training Accuracy= 0.980
Step 460, Minibatch Loss= 0.0386, Training Accuracy= 0.990
Optimization Finished!
('Testing Accuracy:', 0.970425)
done
