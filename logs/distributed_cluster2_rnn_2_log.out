nohup: ignoring input
Using TensorFlow backend.
2019-05-09 23:31:07.225574: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-05-09 23:31:07.253708: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194860000 Hz
2019-05-09 23:31:07.256273: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3ac7fe0 executing computations on platform Host. Devices:
2019-05-09 23:31:07.256307: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-09 23:31:07.257623: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> node0:2272}
2019-05-09 23:31:07.257654: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> node0:2273, 1 -> node1:2274, 2 -> localhost:2275}
2019-05-09 23:31:07.261435: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2275
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:132: __init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.
Instructions for updating:
This class is equivalent as tf.keras.layers.SimpleRNNCell, and will be replaced by that in Tensorflow 2.0.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:133: static_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell, unroll=True)`, which is equivalent to this API
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_basic_rnn_static_clusterspec.py:220: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
INFO:tensorflow:Running local_init_op.
2019-05-09 23:31:10.868545: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session d6ccea4c1a401481 with config: 
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global_step, Variable, Variable_1, rnn/basic_rnn_cell/kernel, rnn/basic_rnn_cell/bias, Variable/RMSProp, Variable/RMSProp_1, Variable_1/RMSProp, Variable_1/RMSProp_1, rnn/basic_rnn_cell/kernel/RMSProp, rnn/basic_rnn_cell/kernel/RMSProp_1, rnn/basic_rnn_cell/bias/RMSProp, rnn/basic_rnn_cell/bias/RMSProp_1
INFO:tensorflow:Running local_init_op.
2019-05-09 23:31:41.008301: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session d0a2e55f1b32e249 with config: 
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting queue runners.
worker
Variables initialized ...
running epochs
Step 10, Minibatch Loss= 0.1122, Training Accuracy= 0.980
Step 20, Minibatch Loss= 0.0405, Training Accuracy= 0.990
Step 30, Minibatch Loss= 0.1225, Training Accuracy= 0.950
Step 40, Minibatch Loss= 0.0099, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0331, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0653, Training Accuracy= 0.980
Step 70, Minibatch Loss= 0.0085, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0309, Training Accuracy= 0.990
Step 90, Minibatch Loss= 0.1030, Training Accuracy= 0.970
Step 100, Minibatch Loss= 0.1036, Training Accuracy= 0.950
Step 110, Minibatch Loss= 0.0329, Training Accuracy= 0.990
Step 120, Minibatch Loss= 0.1353, Training Accuracy= 0.970
Step 130, Minibatch Loss= 0.0611, Training Accuracy= 0.980
Step 140, Minibatch Loss= 0.0945, Training Accuracy= 0.970
Step 150, Minibatch Loss= 0.1098, Training Accuracy= 0.950
Step 160, Minibatch Loss= 0.0165, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0276, Training Accuracy= 0.990
Step 180, Minibatch Loss= 0.0465, Training Accuracy= 0.980
Step 190, Minibatch Loss= 0.0330, Training Accuracy= 0.980
Step 200, Minibatch Loss= 0.0499, Training Accuracy= 0.990
Step 210, Minibatch Loss= 0.0105, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.1177, Training Accuracy= 0.980
Step 230, Minibatch Loss= 0.0814, Training Accuracy= 0.990
Step 240, Minibatch Loss= 0.0542, Training Accuracy= 0.980
Step 250, Minibatch Loss= 0.0801, Training Accuracy= 0.980
Step 260, Minibatch Loss= 0.0083, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0162, Training Accuracy= 1.000
Step 280, Minibatch Loss= 0.0354, Training Accuracy= 0.990
Step 290, Minibatch Loss= 0.0238, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0869, Training Accuracy= 0.950
Step 310, Minibatch Loss= 0.1865, Training Accuracy= 0.940
Step 320, Minibatch Loss= 0.0150, Training Accuracy= 0.990
Step 330, Minibatch Loss= 0.0174, Training Accuracy= 1.000
Step 340, Minibatch Loss= 0.0324, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0451, Training Accuracy= 0.980
Step 360, Minibatch Loss= 0.0563, Training Accuracy= 0.980
Step 370, Minibatch Loss= 0.0259, Training Accuracy= 1.000
Step 380, Minibatch Loss= 0.0463, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0298, Training Accuracy= 0.990
Step 400, Minibatch Loss= 0.0831, Training Accuracy= 0.980
Step 410, Minibatch Loss= 0.0145, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0438, Training Accuracy= 0.980
Step 430, Minibatch Loss= 0.0185, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0155, Training Accuracy= 0.990
Step 450, Minibatch Loss= 0.0849, Training Accuracy= 0.960
Step 460, Minibatch Loss= 0.0331, Training Accuracy= 0.990
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0684, Training Accuracy= 0.980
Step 20, Minibatch Loss= 0.0373, Training Accuracy= 0.990
Step 30, Minibatch Loss= 0.1009, Training Accuracy= 0.980
Step 40, Minibatch Loss= 0.0529, Training Accuracy= 0.970
Step 50, Minibatch Loss= 0.0307, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0804, Training Accuracy= 0.980
Step 70, Minibatch Loss= 0.0046, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0323, Training Accuracy= 0.980
Step 90, Minibatch Loss= 0.0264, Training Accuracy= 1.000
Step 100, Minibatch Loss= 0.0929, Training Accuracy= 0.960
Step 110, Minibatch Loss= 0.0201, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0910, Training Accuracy= 0.990
Step 130, Minibatch Loss= 0.0126, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0687, Training Accuracy= 0.980
Step 150, Minibatch Loss= 0.0107, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0092, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0253, Training Accuracy= 0.990
Step 180, Minibatch Loss= 0.0140, Training Accuracy= 1.000
Step 190, Minibatch Loss= 0.0207, Training Accuracy= 0.990
Step 200, Minibatch Loss= 0.0067, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0037, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0322, Training Accuracy= 0.980
Step 230, Minibatch Loss= 0.0331, Training Accuracy= 0.990
Step 240, Minibatch Loss= 0.0116, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0521, Training Accuracy= 0.970
Step 260, Minibatch Loss= 0.0042, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0334, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0069, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0025, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0045, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0186, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0064, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0135, Training Accuracy= 1.000
Step 340, Minibatch Loss= 0.0094, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0060, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0037, Training Accuracy= 1.000
Step 370, Minibatch Loss= 0.0081, Training Accuracy= 1.000
Step 380, Minibatch Loss= 0.0455, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0405, Training Accuracy= 0.990
Step 400, Minibatch Loss= 0.0400, Training Accuracy= 0.990
Step 410, Minibatch Loss= 0.0072, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0204, Training Accuracy= 1.000
Step 430, Minibatch Loss= 0.0077, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0038, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0073, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0134, Training Accuracy= 1.000
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0100, Training Accuracy= 1.000
Step 20, Minibatch Loss= 0.0049, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0470, Training Accuracy= 0.980
Step 40, Minibatch Loss= 0.0077, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0138, Training Accuracy= 1.000
Step 60, Minibatch Loss= 0.0221, Training Accuracy= 1.000
Step 70, Minibatch Loss= 0.0039, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0181, Training Accuracy= 1.000
Step 90, Minibatch Loss= 0.0491, Training Accuracy= 0.980
Step 100, Minibatch Loss= 0.0076, Training Accuracy= 1.000
Step 110, Minibatch Loss= 0.0159, Training Accuracy= 0.990
Step 120, Minibatch Loss= 0.0306, Training Accuracy= 0.990
Step 130, Minibatch Loss= 0.0134, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0626, Training Accuracy= 0.980
Step 150, Minibatch Loss= 0.0100, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0104, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0143, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0373, Training Accuracy= 0.980
Step 190, Minibatch Loss= 0.0064, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0138, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0032, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0232, Training Accuracy= 0.990
Step 230, Minibatch Loss= 0.0375, Training Accuracy= 0.980
Step 240, Minibatch Loss= 0.0063, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0279, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0042, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0176, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0101, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0036, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0052, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0089, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0049, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0462, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0121, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0133, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0378, Training Accuracy= 0.990
Step 370, Minibatch Loss= 0.0099, Training Accuracy= 1.000
Step 380, Minibatch Loss= 0.0317, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0146, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.0168, Training Accuracy= 1.000
Step 410, Minibatch Loss= 0.0062, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0260, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0042, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0027, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0102, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0057, Training Accuracy= 1.000
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0089, Training Accuracy= 1.000
Step 20, Minibatch Loss= 0.0034, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0406, Training Accuracy= 0.990
Step 40, Minibatch Loss= 0.0047, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0272, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0248, Training Accuracy= 1.000
Step 70, Minibatch Loss= 0.0022, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0153, Training Accuracy= 0.990
Step 90, Minibatch Loss= 0.0279, Training Accuracy= 0.990
Step 100, Minibatch Loss= 0.0124, Training Accuracy= 1.000
Step 110, Minibatch Loss= 0.0137, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0281, Training Accuracy= 0.990
Step 130, Minibatch Loss= 0.0155, Training Accuracy= 0.990
Step 140, Minibatch Loss= 0.0368, Training Accuracy= 0.990
Step 150, Minibatch Loss= 0.0033, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0056, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0078, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0346, Training Accuracy= 0.990
Step 190, Minibatch Loss= 0.0062, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0094, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0039, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0167, Training Accuracy= 0.990
Step 230, Minibatch Loss= 0.0289, Training Accuracy= 0.980
Step 240, Minibatch Loss= 0.0026, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0385, Training Accuracy= 0.980
Step 260, Minibatch Loss= 0.0041, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0369, Training Accuracy= 0.980
Step 280, Minibatch Loss= 0.0041, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0062, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0054, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0080, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0048, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0166, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0105, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0039, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0106, Training Accuracy= 1.000
Step 370, Minibatch Loss= 0.0051, Training Accuracy= 1.000
Step 380, Minibatch Loss= 0.0409, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0086, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.0455, Training Accuracy= 0.980
Step 410, Minibatch Loss= 0.0025, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0226, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0043, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0035, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0045, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0259, Training Accuracy= 0.990
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0138, Training Accuracy= 0.990
Step 20, Minibatch Loss= 0.0054, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0143, Training Accuracy= 1.000
Step 40, Minibatch Loss= 0.0047, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0254, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0265, Training Accuracy= 1.000
Step 70, Minibatch Loss= 0.0065, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0169, Training Accuracy= 1.000
Step 90, Minibatch Loss= 0.0247, Training Accuracy= 0.990
Step 100, Minibatch Loss= 0.0075, Training Accuracy= 1.000
Step 110, Minibatch Loss= 0.0164, Training Accuracy= 0.990
Step 120, Minibatch Loss= 0.0171, Training Accuracy= 0.990
Step 130, Minibatch Loss= 0.0083, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0504, Training Accuracy= 0.970
Step 150, Minibatch Loss= 0.0095, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0029, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0101, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0226, Training Accuracy= 0.990
Step 190, Minibatch Loss= 0.0076, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0080, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0029, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0090, Trai2019-05-09 23:32:30.406145: W tensorflow/core/distributed_runtime/master_session.cc:1363] Timeout for closing worker session
2019-05-09 23:32:30.406221: W tensorflow/core/distributed_runtime/master_session.cc:2029] Unavailable: OS Error
ning Accuracy= 1.000
Step 230, Minibatch Loss= 0.0276, Training Accuracy= 0.990
Step 240, Minibatch Loss= 0.0055, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0062, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0027, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0432, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0027, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0025, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0033, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0100, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0050, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0592, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0047, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0053, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0162, Training Accuracy= 0.990
Step 370, Minibatch Loss= 0.0144, Training Accuracy= 0.990
Step 380, Minibatch Loss= 0.0333, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0056, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.0142, Training Accuracy= 1.000
Step 410, Minibatch Loss= 0.0028, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0266, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0044, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0018, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0068, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0116, Training Accuracy= 1.000
Optimization Finished!
('Testing Accuracy:', 0.970275)
done
