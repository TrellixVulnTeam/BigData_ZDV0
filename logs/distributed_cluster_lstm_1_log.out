nohup: ignoring input
Using TensorFlow backend.
2019-05-09 23:23:18.282369: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 AVX512F FMA
2019-05-09 23:23:18.309932: I tensorflow/core/platform/profile_utils/cpu_utils.cc:94] CPU Frequency: 2194840000 Hz
2019-05-09 23:23:18.312450: I tensorflow/compiler/xla/service/service.cc:150] XLA service 0x3d1e010 executing computations on platform Host. Devices:
2019-05-09 23:23:18.312489: I tensorflow/compiler/xla/service/service.cc:158]   StreamExecutor device (0): <undefined>, <undefined>
2019-05-09 23:23:18.313729: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job ps -> {0 -> node0:2252}
2019-05-09 23:23:18.313753: I tensorflow/core/distributed_runtime/rpc/grpc_channel.cc:252] Initialize GrpcChannelCache for job worker -> {0 -> node0:2253, 1 -> localhost:2254}
2019-05-09 23:23:18.317506: I tensorflow/core/distributed_runtime/rpc/grpc_server_lib.cc:391] Started server with target: grpc://localhost:2254
WARNING:tensorflow:From /usr/local/lib/python2.7/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.
Instructions for updating:
Colocations handled automatically by placer.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_lstm_rnn_dynamic_clusterspec.py:131: dynamic_rnn (from tensorflow.python.ops.rnn) is deprecated and will be removed in a future version.
Instructions for updating:
Please use `keras.layers.RNN(cell)`, which is equivalent to this API
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_lstm_rnn_dynamic_clusterspec.py:137: batch_normalization (from tensorflow.python.layers.normalization) is deprecated and will be removed in a future version.
Instructions for updating:
Use keras.layers.batch_normalization instead.
WARNING:tensorflow:From /users/madanraj/BigData-master/code/distributed_lstm_rnn_dynamic_clusterspec.py:212: __init__ (from tensorflow.python.training.supervisor) is deprecated and will be removed in a future version.
Instructions for updating:
Please switch to tf.train.MonitoredTrainingSession
INFO:tensorflow:Running local_init_op.
2019-05-09 23:23:22.236965: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 2d4772e87f407e70 with config: 
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Waiting for model to be ready.  Ready_for_local_init_op:  None, ready: Variables not initialized: global_step, rnn/lstm_cell/kernel, rnn/lstm_cell/bias, batch_normalization/gamma, batch_normalization/beta, batch_normalization/moving_mean, batch_normalization/moving_variance, dense/kernel, dense/bias, rnn/lstm_cell/kernel/RMSProp, rnn/lstm_cell/kernel/RMSProp_1, rnn/lstm_cell/bias/RMSProp, rnn/lstm_cell/bias/RMSProp_1, batch_normalization/gamma/RMSProp, batch_normalization/gamma/RMSProp_1, batch_normalization/beta/RMSProp, batch_normalization/beta/RMSProp_1, dense/kernel/RMSProp, dense/kernel/RMSProp_1, dense/bias/RMSProp, dense/bias/RMSProp_1
INFO:tensorflow:Running local_init_op.
2019-05-09 23:23:52.362323: I tensorflow/core/distributed_runtime/master_session.cc:1192] Start master session 60a3422b58e905e5 with config: 
INFO:tensorflow:Done running local_init_op.
INFO:tensorflow:Starting queue runners.
worker

WARNING: The TensorFlow contrib module will not be included in TensorFlow 2.0.
For more information, please see:
  * https://github.com/tensorflow/community/blob/master/rfcs/20180907-contrib-sunset.md
  * https://github.com/tensorflow/addons
If you depend on functionality not listed there, please file an issue.

dense/kernel:0
dense/bias:0
Variables initialized ...
running epochs
Step 10, Minibatch Loss= 0.3743, Training Accuracy= 0.890
Step 20, Minibatch Loss= 0.2955, Training Accuracy= 0.890
Step 30, Minibatch Loss= 0.3743, Training Accuracy= 0.880
Step 40, Minibatch Loss= 0.3124, Training Accuracy= 0.900
Step 50, Minibatch Loss= 0.3209, Training Accuracy= 0.870
Step 60, Minibatch Loss= 0.3371, Training Accuracy= 0.920
Step 70, Minibatch Loss= 0.2242, Training Accuracy= 0.930
Step 80, Minibatch Loss= 0.3053, Training Accuracy= 0.900
Step 90, Minibatch Loss= 0.1751, Training Accuracy= 0.960
Step 100, Minibatch Loss= 0.1390, Training Accuracy= 0.990
Step 110, Minibatch Loss= 0.1609, Training Accuracy= 0.970
Step 120, Minibatch Loss= 0.1967, Training Accuracy= 0.940
Step 130, Minibatch Loss= 0.2736, Training Accuracy= 0.900
Step 140, Minibatch Loss= 0.2352, Training Accuracy= 0.930
Step 150, Minibatch Loss= 0.1978, Training Accuracy= 0.960
Step 160, Minibatch Loss= 0.1419, Training Accuracy= 0.970
Step 170, Minibatch Loss= 0.0990, Training Accuracy= 0.970
Step 180, Minibatch Loss= 0.2170, Training Accuracy= 0.920
Step 190, Minibatch Loss= 0.2732, Training Accuracy= 0.900
Step 200, Minibatch Loss= 0.1310, Training Accuracy= 0.960
Step 210, Minibatch Loss= 0.0931, Training Accuracy= 0.980
Step 220, Minibatch Loss= 0.1241, Training Accuracy= 0.950
Step 230, Minibatch Loss= 0.1722, Training Accuracy= 0.950
Step 240, Minibatch Loss= 0.0949, Training Accuracy= 0.970
Step 250, Minibatch Loss= 0.1191, Training Accuracy= 0.970
Step 260, Minibatch Loss= 0.1236, Training Accuracy= 0.960
Step 270, Minibatch Loss= 0.0940, Training Accuracy= 0.980
Step 280, Minibatch Loss= 0.0800, Training Accuracy= 0.990
Step 290, Minibatch Loss= 0.0658, Training Accuracy= 0.990
Step 300, Minibatch Loss= 0.1681, Training Accuracy= 0.960
Step 310, Minibatch Loss= 0.1442, Training Accuracy= 0.960
Step 320, Minibatch Loss= 0.0726, Training Accuracy= 0.990
Step 330, Minibatch Loss= 0.1484, Training Accuracy= 0.960
Step 340, Minibatch Loss= 0.0853, Training Accuracy= 0.980
Step 350, Minibatch Loss= 0.0840, Training Accuracy= 0.970
Step 360, Minibatch Loss= 0.0806, Training Accuracy= 0.980
Step 370, Minibatch Loss= 0.1403, Training Accuracy= 0.960
Step 380, Minibatch Loss= 0.0721, Training Accuracy= 0.970
Step 390, Minibatch Loss= 0.1232, Training Accuracy= 0.960
Step 400, Minibatch Loss= 0.1132, Training Accuracy= 0.980
Step 410, Minibatch Loss= 0.1012, Training Accuracy= 0.960
Step 420, Minibatch Loss= 0.1212, Training Accuracy= 0.950
Step 430, Minibatch Loss= 0.1507, Training Accuracy= 0.940
Step 440, Minibatch Loss= 0.0403, Training Accuracy= 0.990
Step 450, Minibatch Loss= 0.0308, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.1534, Training Accuracy= 0.960
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.1079, Training Accuracy= 0.960
Step 20, Minibatch Loss= 0.0330, Training Accuracy= 0.990
Step 30, Minibatch Loss= 0.1059, Training Accuracy= 0.960
Step 40, Minibatch Loss= 0.0214, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0619, Training Accuracy= 0.980
Step 60, Minibatch Loss= 0.1642, Training Accuracy= 0.970
Step 70, Minibatch Loss= 0.0441, Training Accuracy= 0.990
Step 80, Minibatch Loss= 0.1148, Training Accuracy= 0.940
Step 90, Minibatch Loss= 0.0761, Training Accuracy= 0.970
Step 100, Minibatch Loss= 0.0336, Training Accuracy= 0.990
Step 110, Minibatch Loss= 0.0721, Training Accuracy= 0.980
Step 120, Minibatch Loss= 0.1047, Training Accuracy= 0.970
Step 130, Minibatch Loss= 0.1037, Training Accuracy= 0.980
Step 140, Minibatch Loss= 0.1335, Training Accuracy= 0.970
Step 150, Minibatch Loss= 0.1325, Training Accuracy= 0.950
Step 160, Minibatch Loss= 0.0213, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0242, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0777, Training Accuracy= 0.990
Step 190, Minibatch Loss= 0.0440, Training Accuracy= 0.980
Step 200, Minibatch Loss= 0.0215, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0417, Training Accuracy= 0.990
Step 220, Minibatch Loss= 0.0575, Training Accuracy= 0.980
Step 230, Minibatch Loss= 0.0948, Training Accuracy= 0.970
Step 240, Minibatch Loss= 0.0217, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0313, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0383, Training Accuracy= 0.990
Step 270, Minibatch Loss= 0.0665, Training Accuracy= 0.980
Step 280, Minibatch Loss= 0.0344, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0117, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0296, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.1178, Training Accuracy= 0.970
Step 320, Minibatch Loss= 0.0180, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0404, Training Accuracy= 0.990
Step 340, Minibatch Loss= 0.0204, Training Accuracy= 0.990
Step 350, Minibatch Loss= 0.0184, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0396, Training Accuracy= 0.980
Step 370, Minibatch Loss= 0.0958, Training Accuracy= 0.980
Step 380, Minibatch Loss= 0.0255, Training Accuracy= 1.000
Step 390, Minibatch Loss= 0.0988, Training Accuracy= 0.970
Step 400, Minibatch Loss= 0.0708, Training Accuracy= 0.990
Step 410, Minibatch Loss= 0.0169, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0289, Training Accuracy= 0.990
Step 430, Minibatch Loss= 0.0159, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0188, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0324, Training Accuracy= 0.990
Step 460, Minibatch Loss= 0.0299, Training Accuracy= 1.000
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0686, Training Accuracy= 0.980
Step 20, Minibatch Loss= 0.0136, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0696, Training Accuracy= 0.990
Step 40, Minibatch Loss= 0.0152, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0262, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.1307, Training Accuracy= 0.950
Step 70, Minibatch Loss= 0.0085, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0463, Training Accuracy= 0.990
Step 90, Minibatch Loss= 0.0873, Training Accuracy= 0.980
Step 100, Minibatch Loss= 0.0259, Training Accuracy= 1.000
Step 110, Minibatch Loss= 0.0294, Training Accuracy= 0.990
Step 120, Minibatch Loss= 0.0535, Training Accuracy= 0.980
Step 130, Minibatch Loss= 0.0213, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0439, Training Accuracy= 0.990
Step 150, Minibatch Loss= 0.0186, Training Accuracy= 0.990
Step 160, Minibatch Loss= 0.0129, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0279, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0967, Training Accuracy= 0.970
Step 190, Minibatch Loss= 0.0136, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0113, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0062, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0171, Training Accuracy= 1.000
Step 230, Minibatch Loss= 0.0472, Training Accuracy= 0.980
Step 240, Minibatch Loss= 0.0077, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0236, Training Accuracy= 0.990
Step 260, Minibatch Loss= 0.0143, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0297, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0119, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0109, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0117, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0182, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0074, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0116, Training Accuracy= 1.000
Step 340, Minibatch Loss= 0.0044, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0123, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0194, Training Accuracy= 0.990
Step 370, Minibatch Loss= 0.0493, Training Accuracy= 0.990
Step 380, Minibatch Loss= 0.0391, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0276, Training Accuracy= 0.990
Step 400, Minibatch Loss= 0.0302, Training Accuracy= 0.990
Step 410, Minibatch Loss= 0.0052, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0176, Training Accuracy= 1.000
Step 430, Minibatch Loss= 0.0066, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0101, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0108, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0386, Training Accuracy= 0.980
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0219, Training Accuracy= 0.990
Step 20, Minibatch Loss= 0.0145, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0391, Training Accuracy= 0.990
Step 40, Minibatch Loss= 0.0086, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0327, Training Accuracy= 0.990
Step 60, Minibatch Loss= 0.0478, Training Accuracy= 0.970
Step 70, Minibatch Loss= 0.0022, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0179, Training Accuracy= 1.000
Step 90, Minibatch Loss= 0.0108, Training Accuracy= 1.000
Step 100, Minibatch Loss= 0.0205, Training Accuracy= 0.990
Step 110, Minibatch Loss= 0.0048, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0465, Training Accuracy= 0.980
Step 130, Minibatch Loss= 0.0082, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0312, Training Accuracy= 0.990
Step 150, Minibatch Loss= 0.0298, Training Accuracy= 0.990
Step 160, Minibatch Loss= 0.0060, Training Accuracy= 1.000
Step 170, Minibatch Loss= 0.0114, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0317, Training Accuracy= 1.000
Step 190, Minibatch Loss= 0.0079, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0060, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0030, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0054, Training Accuracy= 1.000
Step 230, Minibatch Loss= 0.0193, Training Accuracy= 1.000
Step 240, Minibatch Loss= 0.0078, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0131, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0060, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0356, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0050, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0055, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0231, Training Accuracy= 0.990
Step 310, Minibatch Loss= 0.0091, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0055, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0218, Training Accuracy= 1.000
Step 340, Minibatch Loss= 0.0040, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0059, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0099, Training Accuracy= 1.000
Step 370, Minibatch Loss= 0.0237, Training Accuracy= 0.990
Step 380, Minibatch Loss= 0.0353, Training Accuracy= 0.990
Step 390, Minibatch Loss= 0.0197, Training Accuracy= 0.990
Step 400, Minibatch Loss= 0.0165, Training Accuracy= 0.990
Step 410, Minibatch Loss= 0.0051, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0075, Training Accuracy= 1.000
Step 430, Minibatch Loss= 0.0036, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0061, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0049, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0201, Training Accuracy= 1.000
Optimization Finished!
running epochs
Step 10, Minibatch Loss= 0.0073, Training Accuracy= 1.000
Step 20, Minibatch Loss= 0.0047, Training Accuracy= 1.000
Step 30, Minibatch Loss= 0.0197, Training Accuracy= 0.990
Step 40, Minibatch Loss= 0.0080, Training Accuracy= 1.000
Step 50, Minibatch Loss= 0.0180, Training Accuracy= 1.000
Step 60, Minibatch Loss= 0.0208, Training Accuracy= 1.000
Step 70, Minibatch Loss= 0.0024, Training Accuracy= 1.000
Step 80, Minibatch Loss= 0.0116, Training Accuracy= 1.000
Step 90, Minibatch Loss= 0.0091, Training Accuracy= 1.000
Step 100, Minibatch Loss= 0.0123, Training Accuracy= 0.990
Step 110, Minibatch Loss= 0.0028, Training Accuracy= 1.000
Step 120, Minibatch Loss= 0.0461, Training Accuracy= 0.980
Step 130, Minibatch Loss= 0.0100, Training Accuracy= 1.000
Step 140, Minibatch Loss= 0.0061, Training Accuracy= 1.000
Step 150, Minibatch Loss= 0.0045, Training Accuracy= 1.000
Step 160, Minibatch Loss= 0.0030, Training Accura2019-05-09 23:26:38.597944: W tensorflow/core/distributed_runtime/master_session.cc:2029] Unavailable: OS Error
cy= 1.000
Step 170, Minibatch Loss= 0.0065, Training Accuracy= 1.000
Step 180, Minibatch Loss= 0.0200, Training Accuracy= 0.990
Step 190, Minibatch Loss= 0.0071, Training Accuracy= 1.000
Step 200, Minibatch Loss= 0.0079, Training Accuracy= 1.000
Step 210, Minibatch Loss= 0.0016, Training Accuracy= 1.000
Step 220, Minibatch Loss= 0.0028, Training Accuracy= 1.000
Step 230, Minibatch Loss= 0.0121, Training Accuracy= 1.000
Step 240, Minibatch Loss= 0.0034, Training Accuracy= 1.000
Step 250, Minibatch Loss= 0.0067, Training Accuracy= 1.000
Step 260, Minibatch Loss= 0.0029, Training Accuracy= 1.000
Step 270, Minibatch Loss= 0.0196, Training Accuracy= 0.990
Step 280, Minibatch Loss= 0.0034, Training Accuracy= 1.000
Step 290, Minibatch Loss= 0.0029, Training Accuracy= 1.000
Step 300, Minibatch Loss= 0.0033, Training Accuracy= 1.000
Step 310, Minibatch Loss= 0.0049, Training Accuracy= 1.000
Step 320, Minibatch Loss= 0.0039, Training Accuracy= 1.000
Step 330, Minibatch Loss= 0.0038, Training Accuracy= 1.000
Step 340, Minibatch Loss= 0.0045, Training Accuracy= 1.000
Step 350, Minibatch Loss= 0.0045, Training Accuracy= 1.000
Step 360, Minibatch Loss= 0.0043, Training Accuracy= 1.000
Step 370, Minibatch Loss= 0.0168, Training Accuracy= 0.990
Step 380, Minibatch Loss= 0.0086, Training Accuracy= 1.000
Step 390, Minibatch Loss= 0.0119, Training Accuracy= 1.000
Step 400, Minibatch Loss= 0.0063, Training Accuracy= 1.000
Step 410, Minibatch Loss= 0.0021, Training Accuracy= 1.000
Step 420, Minibatch Loss= 0.0069, Training Accuracy= 1.000
Step 430, Minibatch Loss= 0.0022, Training Accuracy= 1.000
Step 440, Minibatch Loss= 0.0057, Training Accuracy= 1.000
Step 450, Minibatch Loss= 0.0033, Training Accuracy= 1.000
Step 460, Minibatch Loss= 0.0085, Training Accuracy= 1.000
Optimization Finished!
('Testing Accuracy:', 0.9846)
done
